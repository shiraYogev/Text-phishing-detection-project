{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Baseline: dummy classifier**\n",
        "A description of the execution of the simplest baseline, model that always predicting the majority class"
      ],
      "metadata": {
        "id": "YdFYuCQQ918w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVFOOGp49vj5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, recall_score\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the phishing dataset\n",
        "dataset = load_dataset(\"ealvaradob/phishing-dataset\", \"texts\", trust_remote_code=True)\n",
        "\n",
        "# Check the structure of the dataset\n",
        "print(\"Dataset Head:\")\n",
        "print(dataset['train'][:5])  # Print the first 5 entries of the dataset\n",
        "\n",
        "# Extract text and labels\n",
        "texts = [example['text'] for example in dataset['train']]\n",
        "labels = [example['label'] for example in dataset['train']]\n",
        "\n",
        "# Convert to DataFrame for better visualization and sanity check\n",
        "df = pd.DataFrame({'text': texts, 'label': labels})\n",
        "print(\"\\nDataFrame Head:\")\n",
        "print(df.head())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "new_random_state = 21  # Change this value to create a new split\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=new_random_state)\n",
        "\n",
        "# Print heads of split datasets to ensure proper division\n",
        "print(\"\\nTraining Set Head:\")\n",
        "print(pd.DataFrame({'text': X_train[:5], 'label': y_train[:5]}))\n",
        "\n",
        "print(\"\\nTesting SetHead:\")\n",
        "print(pd.DataFrame({'text': X_test[:5], 'label': y_test[:5]}))\n",
        "\n",
        "# Train a Dummy Classifier with 'most_frequent' strategy (predicts the most frequent class)\n",
        "classifier = DummyClassifier(strategy=\"most_frequent\")  # \"most_frequent\" will predict the most common label\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"\\nPredict Set Head:\")\n",
        "print(pd.DataFrame({'text': X_test[:5], 'label': y_pred[:5]}))\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' for imbalanced datasets\n",
        "recall = recall_score(y_test, y_pred, average='weighted')  # Use 'weighted' for imbalanced datasets\n",
        "\n",
        "print(\"\\nEvaluation Metrics with Dummy Classifier:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Recall Score: {recall:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the model for future use\n",
        "import joblib\n",
        "joblib.dump(classifier, \"dummy_classifier_no_bow.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Training Set Head:\n",
        "                                                text  label\n",
        "0  draft strawman as requested . i ' ll work on a...      0\n",
        "1  re : unify brent , as i have indicated to both...      0\n",
        "2  On Sat, 27 Jul 2002, Adam L. Beberg wrote:> On...      0\n",
        "3  From: Matt Kettler > Hmm, I think that Marc, b...      0\n",
        "4  midamerica ling conf 98 the schedule for the m...      0\n",
        "\n",
        "Testing Set Head:\n",
        "                                                text  label\n",
        "0  online drugs - save up to 80 % online pharmacy...      1\n",
        "1   if anyone calling from a mobile Co. and asks ...      0\n",
        "2  status of hpl transfers to aep sally , please ...      0\n",
        "3  she ' s not happy if your not king size 2 m 6 ...      1\n",
        "4  Shit that is really shocking and scary, cant i...      0\n",
        "\n",
        "Predict Set Head:\n",
        "                                                text  label\n",
        "0  online drugs - save up to 80 % online pharmacy...      0\n",
        "1   if anyone calling from a mobile Co. and asks ...      0\n",
        "2  status of hpl transfers to aep sally , please ...      0\n",
        "3  she ' s not happy if your not king size 2 m 6 ...      0\n",
        "4  Shit that is really shocking and scary, cant i...      0\n",
        "\n",
        "Evaluation Metrics with Dummy Classifier:\n",
        "Accuracy: 0.6130\n",
        "F1 Score: 0.4659\n",
        "Recall Score: 0.6130\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.61      1.00      0.76      2469\n",
        "           1       0.00      0.00      0.00      1559\n",
        "\n",
        "    accuracy                           0.61      4028\n",
        "   macro avg       0.31      0.50      0.38      4028\n",
        "weighted avg       0.38      0.61      0.47      4028\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "q-fD4Hrz-YuZ"
      }
    }
  ]
}